{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6Y0EbiOb29c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = 100000\n",
        "max_len = 50\n",
        "batch_size = 64\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWkja4Lvdfbz",
        "outputId": "ac8c7e28-8419-4861-830c-34610494da05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep8rnj8te3yd",
        "outputId": "8ac3d73b-a388-40d9-bb2d-979322d2dc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2071,   56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,\n",
              "         21,  134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,\n",
              "         36,   28,  224,   92,   25,  104,    4,  226,   65,   16,   38,\n",
              "       1334,   88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,\n",
              "         15,   16, 5345,   19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data= sequence.pad_sequences(train_data, maxlen= max_len)\n",
        "test_data= sequence.pad_sequences(test_data, maxlen= max_len)"
      ],
      "metadata": {
        "id": "JSMpSxlGe-EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim= max_len, output_dim= batch_size),\n",
        "    tf.keras.layers.LSTM(units= batch_size),\n",
        "    tf.keras.layers.Dense(units= 1, activation= \"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "dUfAMgl5nLOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P2hMUs-xuEt",
        "outputId": "058d7528-6536-4e29-d1c7-28689fb11f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          3200      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36289 (141.75 KB)\n",
            "Trainable params: 36289 (141.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss=tf.keras.losses.BinaryCrossentropy(), metrics=\"acc\")"
      ],
      "metadata": {
        "id": "2IQBH9u5x-IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=train_data, y= train_labels, batch_size= batch_size, epochs=20, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWbPgKLLyQGO",
        "outputId": "5ac68fd2-5ae9-4158-b04f-04a3930bb6a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 19s 54ms/step - loss: 0.6451 - acc: 0.6231 - val_loss: 0.6572 - val_acc: 0.6160\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6439 - acc: 0.6259 - val_loss: 0.6608 - val_acc: 0.6184\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6426 - acc: 0.6223 - val_loss: 0.6541 - val_acc: 0.6210\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6415 - acc: 0.6245 - val_loss: 0.6566 - val_acc: 0.6108\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6406 - acc: 0.6269 - val_loss: 0.6508 - val_acc: 0.6190\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6391 - acc: 0.6259 - val_loss: 0.6509 - val_acc: 0.6176\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6379 - acc: 0.6323 - val_loss: 0.6636 - val_acc: 0.5990\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6367 - acc: 0.6315 - val_loss: 0.6478 - val_acc: 0.6226\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6347 - acc: 0.6352 - val_loss: 0.6495 - val_acc: 0.6184\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6331 - acc: 0.6317 - val_loss: 0.6525 - val_acc: 0.6168\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6317 - acc: 0.6362 - val_loss: 0.6555 - val_acc: 0.6148\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6297 - acc: 0.6382 - val_loss: 0.6462 - val_acc: 0.6250\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6275 - acc: 0.6393 - val_loss: 0.6475 - val_acc: 0.6268\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6257 - acc: 0.6438 - val_loss: 0.6480 - val_acc: 0.6274\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6236 - acc: 0.6445 - val_loss: 0.6496 - val_acc: 0.6258\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6212 - acc: 0.6463 - val_loss: 0.6450 - val_acc: 0.6298\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6186 - acc: 0.6489 - val_loss: 0.6487 - val_acc: 0.6290\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6166 - acc: 0.6554 - val_loss: 0.6466 - val_acc: 0.6286\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6132 - acc: 0.6568 - val_loss: 0.6471 - val_acc: 0.6270\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6103 - acc: 0.6578 - val_loss: 0.6507 - val_acc: 0.6196\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b4446412980>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84X7CBOSzg6C",
        "outputId": "9c26acac-a21f-409e-a036-1765551dc1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 4ms/step - loss: 0.6583 - acc: 0.6128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6582735776901245, 0.6127600073814392]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens], max_len)[0]\n"
      ],
      "metadata": {
        "id": "KtuaoqTR0xct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,max_len))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred, verbose=0)\n",
        "  if result[0] > 0.5:\n",
        "    print(\"Positive\", result[0])\n",
        "  else:\n",
        "    print(\"Negative\", result[0])\n",
        "\n",
        "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review = \"that movie really sucks sucks sucks sucks. I really hate hate suck this. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
        "predict(negative_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sso4pok043X",
        "outputId": "593b1cd7-7aa4-4b94-95a4-81390aba0f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive [0.5489679]\n",
            "Positive [0.5444149]\n"
          ]
        }
      ]
    }
  ]
}